"""
MCPReconX - Tool Injection Exploit
===================================
Proof-of-concept for tool poisoning/tool injection vulnerabilities.

ETHICAL USE NOTICE:
This tool is intended for authorized security testing only.
"""

import asyncio
import json
from datetime import datetime
from typing import Dict, Any

from .poc_template import ExploitTemplate, ExploitResult


class ToolInjectionExploit(ExploitTemplate):
    """
    Exploit for tool injection/poisoning vulnerabilities.
    
    This demonstrates how malicious instructions in tool descriptions
    can lead to prompt injection attacks.
    """
    
    name = "tool_injection"
    description = "Tool poisoning via malicious description injection"
    vulnerability_id = "MCP-INJ-001"
    severity = "critical"
    cvss_score = 9.1
    
    # Safe test payloads (never actually harmful)
    TEST_PAYLOADS = [
        "MCPReconX_TEST_INJECTION_MARKER",
        "__mcpreconx_injection_test__",
    ]
    
    async def check_vulnerable(self) -> bool:
        """Check if target has tool injection vulnerability."""
        self.logger.info("Checking for tool injection vulnerability...")
        
        # Get tools list
        response = await self.send_jsonrpc("tools/list", msg_id=1)
        
        if not response or "result" not in response:
            return False
        
        tools = response["result"].get("tools", [])
        
        # Check for tools that accept string parameters
        for tool in tools:
            schema = tool.get("inputSchema", {})
            properties = schema.get("properties", {})
            
            for prop_name, prop_spec in properties.items():
                if prop_spec.get("type") == "string":
                    # Found a string parameter - potential injection point
                    return True
        
        return False
    
    async def exploit(self, safe_mode: bool = True) -> ExploitResult:
        """
        Execute tool injection PoC.
        
        Args:
            safe_mode: If True, only simulate the exploit
        """
        self.logger.info(f"Executing tool injection exploit (safe_mode={safe_mode})")
        
        timestamp = datetime.now().isoformat()
        
        if safe_mode:
            # Simulation mode - document what would happen
            return ExploitResult(
                success=True,
                vulnerability_id=self.vulnerability_id,
                details={
                    "exploit_type": "tool_injection",
                    "simulation": True,
                    "description": "Tool injection vulnerability detected",
                    "attack_vector": "Malicious payload in tool parameter",
                    "potential_impact": [
                        "Prompt injection",
                        "System instruction override",
                        "Unauthorized action execution"
                    ],
                    "test_payloads": self.TEST_PAYLOADS,
                    "note": "This is a simulation. No actual injection performed."
                },
                evidence="Tool accepts string parameters without proper validation",
                timestamp=timestamp
            )
        
        # Active mode - would attempt safe test
        # In practice, this would use a completely benign test payload
        return ExploitResult(
            success=False,  # Safe test should not succeed
            vulnerability_id=self.vulnerability_id,
            details={
                "exploit_type": "tool_injection",
                "simulation": False,
                "note": "Safe test executed - no injection performed",
                "test_payload": self.TEST_PAYLOADS[0]
            },
            evidence="Safe test completed without code execution",
            timestamp=timestamp
        )
    
    def get_remediation(self) -> str:
        """Return remediation advice."""
        return """
Tool Injection Remediation:

1. Input Validation:
   - Validate all tool parameters against expected schemas
   - Use allowlists for acceptable input patterns
   - Reject suspicious characters and patterns

2. Sandboxing:
   - Execute tool logic in isolated environments
   - Use containerization or sandboxing technologies
   - Limit tool access to system resources

3. Prompt Security:
   - Sanitize tool descriptions before display
   - Use structured prompts that resist injection
   - Implement prompt boundaries and delimiters

4. Access Control:
   - Restrict tool registration to authorized users
   - Audit tool definitions for malicious content
   - Implement code review for tool implementations

5. Monitoring:
   - Log all tool invocations
   - Monitor for anomalous tool usage patterns
   - Alert on suspicious parameter values
        """
